{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "425fb020-e864-40ce-a31f-8da40c73d14b",
   "metadata": {},
   "source": [
    "# Agentic RAG (Retreieval Augmented Generation) System using Amazon Bedrock Knowledge Bases and LangGraph\n",
    "\n",
    "This notebook implements a self-corrective RAG (Retrieval-Augmented Generation) workflow using strands agent for orchestration. The system uses several advanced techniques to improve answer accuracy:\n",
    "\n",
    "1. **Query expansion** - Looks up domain terms to transform queries with added context\n",
    "2. **Query decomposition** - Breaks down complex questions when needed\n",
    "3. **Response quality** - Evaluates if responses quality is accceptable\n",
    "4. **Self-correction** - Evaluates response quality and relevance, taking corrective action if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c60e80b",
   "metadata": {},
   "source": [
    "## Pre-requisites\n",
    "1. Run notebook 1 (01-setup-create-insert-dynamodb.ipynb) to create and populate the DynamoDB table, with sample lookup data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8ce599",
   "metadata": {},
   "source": [
    "## Import Stored Variables\n",
    "\n",
    "Retrieve the DynamoDB table name from the previous notebook using Jupyter's `%store -r` magic command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bec6b5cd-65f8-4fd6-8025-d926d3cd095a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no stored variable or alias table_name\n"
     ]
    }
   ],
   "source": [
    "%store -r table_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39ab109-5797-4773-8053-2fd2cc9e9ff4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Install Required Libraries\n",
    "\n",
    "Install necessary packages for implementing the RAG system:\n",
    "- strands for building AI agents\n",
    "- boto3 for python AWS SDK\n",
    "- Other utility libraries for handling asynchronous operations, logging, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "969fb438",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --force-reinstall -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69193bff-d933-47ed-865d-6f827f28dc17",
   "metadata": {},
   "source": [
    "NOTE: Make sure to manually restart the notebook after installing packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6256865e-d780-4869-b7fb-baafc897e395",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>Jupyter.notebook.kernel.restart()</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # restart kernel\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585b831b",
   "metadata": {},
   "source": [
    "## Configure Amazon Bedrock Services\n",
    "\n",
    "Set up the Amazon Bedrock services:\n",
    "1. Choose the foundation model (Claude 3 Sonnet in this case)\n",
    "2. Configure the AWS region\n",
    "3. Initialize Bedrock clients (runtime and agent-runtime)\n",
    "4. Set the Knowledge Base ID for RAG retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "35d0ffc1-b5ba-4f20-8da0-401a6e8f7789",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using modelId: us.anthropic.claude-haiku-4-5-20251001-v1:0\n"
     ]
    }
   ],
   "source": [
    "# Model configurations (used for query expansion)\n",
    "\n",
    "#modelId = 'anthropic.claude-3-sonnet-20240229-v1:0'\n",
    "modelId = 'us.anthropic.claude-haiku-4-5-20251001-v1:0'\n",
    "print(f'Using modelId: {modelId}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "642ca11c-35fe-4af8-8744-214093a4a44f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NewProfile:\n"
     ]
    }
   ],
   "source": [
    "! echo $AWS_PROFILE\n",
    "! AWS_PROFILE=None\n",
    "! echo 'NewProfile:'$AWS_PROFILE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92897aef",
   "metadata": {},
   "source": [
    "## Connecting to AWS Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a0dbd634",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old Profile:None\n",
      "New Profile:None\n",
      "=== AWS Connection Test ===\n",
      "‚úì AWS connection successful!\n",
      "Account: 211125637749\n",
      "User/Role: arn:aws:sts::211125637749:assumed-role/AmazonSageMaker-ExecutionRole-20251107T111685/SageMaker\n",
      "Region: us-west-2\n",
      "‚úì All AWS clients created successfully!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('us-west-2', '211125637749')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pprint\n",
    "import boto3\n",
    "import json, sys\n",
    "from datetime import datetime\n",
    "import json\n",
    "import time\n",
    "import boto3\n",
    "import asyncio\n",
    "import logging\n",
    "import inspect\n",
    "from typing import List\n",
    "\n",
    "# Strands Agents imports\n",
    "from strands import Agent, tool\n",
    "\n",
    "from utils.knowledge_base import BedrockKnowledgeBase\n",
    "\n",
    "print(f\"Old Profile:{os.environ.get('AWS_PROFILE')}\")\n",
    "os.environ.pop('AWS_PROFILE', None)\n",
    "print(f\"New Profile:{os.environ.get('AWS_PROFILE')}\")\n",
    "\n",
    "\n",
    "# Clear any cached credentials in boto3\n",
    "#boto3.DEFAULT_SESSION = None\n",
    "\n",
    "# Uncomment and set your AWS profile if using a named profile\n",
    "# import os\n",
    "#os.environ['AWS_PROFILE'] = 'heyjack+autotecture-Admin'\n",
    "#os.environ['AWS_DEFAULT_REGION'] = 'us-west-2'\n",
    "\n",
    "# Create a fresh session\n",
    "session = boto3.Session()\n",
    "region = session.region_name\n",
    "\n",
    "print(\"=== AWS Connection Test ===\")\n",
    "try:\n",
    "    # Test AWS connection first\n",
    "    sts_client = session.client('sts')\n",
    "    identity = sts_client.get_caller_identity()\n",
    "    account_id = identity[\"Account\"]\n",
    "    print(f\"‚úì AWS connection successful!\")\n",
    "    print(f\"Account: {account_id}\")\n",
    "    print(f\"User/Role: {identity.get('Arn')}\")\n",
    "    print(f\"Region: {region}\")\n",
    "    \n",
    "    # Create AWS clients using the session\n",
    "    s3_client = session.client('s3')\n",
    "    bedrock = session.client(\n",
    "        service_name = 'bedrock-runtime',\n",
    "        region_name = region,\n",
    "    )\n",
    "    bedrock_agent_client = session.client('bedrock-agent')\n",
    "    bedrock_agent_runtime_client = session.client('bedrock-agent-runtime')\n",
    "    \n",
    "    print(\"‚úì All AWS clients created successfully!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚úó AWS connection failed: {e}\")\n",
    "    print(\"\\n=== TROUBLESHOOTING ===\")\n",
    "    print(\"1. Restart Jupyter kernel: Kernel ‚Üí Restart Kernel\")\n",
    "    print(\"2. Check AWS profile: aws configure list\")\n",
    "    print(\"3. Test in terminal: aws sts get-caller-identity\")\n",
    "    print(\"4. Set profile: os.environ['AWS_PROFILE'] = 'your-profile'\")\n",
    "    raise\n",
    "\n",
    "logging.basicConfig(format='[%(asctime)s] p%(process)s {%(filename)s:%(lineno)d} %(levelname)s - %(message)s', level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "region, account_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3dcd05a",
   "metadata": {},
   "source": [
    "## Set up for creating a Knowledge Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "29636bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Get the current timestamp\n",
    "current_time = time.time()\n",
    "\n",
    "# Format the timestamp as a string\n",
    "timestamp_str = time.strftime(\"%Y%m%d%H%M%S\", time.localtime(current_time))[-7:]\n",
    "# Create the suffix using the timestamp\n",
    "suffix = f\"{timestamp_str}\"\n",
    "\n",
    "knowledge_base_name = f\"bedrock-kb-corrective-rag-{suffix}\"\n",
    "knowledge_base_description = \"Octank financial data with s3 as data source.\"\n",
    "\n",
    "bucket_name = f'{knowledge_base_name}-{account_id}'\n",
    "\n",
    "data_bucket_name = f'bedrock-kb-{suffix}-1' # replace it with your first bucket name.\n",
    "\n",
    "data_sources=[{\"type\": \"S3\", \"bucket_name\": data_bucket_name}]\n",
    "                \n",
    "pp = pprint.PrettyPrinter(indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe6b5e7",
   "metadata": {},
   "source": [
    "### Creating Knowledge Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81367e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "knowledge_base = BedrockKnowledgeBase(\n",
    "    kb_name=f'{knowledge_base_name}',\n",
    "    kb_description=knowledge_base_description,\n",
    "    data_sources=data_sources,\n",
    "    chunking_strategy = \"FIXED_SIZE\", \n",
    "    suffix = f'{suffix}-f'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b38b56",
   "metadata": {},
   "source": [
    "#### Upload data to S3 Bucket data source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a8ce523b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping file ./synthetic_dataset/podcastdemo.mp3\n",
      "Skipping file ./synthetic_dataset/LICENSE\n",
      "Skipping file ./synthetic_dataset/NOTICE\n",
      "Skipping file ./synthetic_dataset/README.md\n",
      "Skipping file ./synthetic_dataset/bda.m4v\n",
      "uploading file ./synthetic_dataset/octank_financial_10K.pdf to bedrock-kb-2150725-1\n"
     ]
    }
   ],
   "source": [
    "def upload_directory(path, bucket_name):\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            file_to_upload = os.path.join(root, file)\n",
    "            if file not in [\"LICENSE\", \"NOTICE\", \"README.md\", \"podcastdemo.mp3\",\"bda.m4v\"]:\n",
    "                print(f\"uploading file {file_to_upload} to {bucket_name}\")\n",
    "                s3_client.upload_file(file_to_upload, bucket_name, file)\n",
    "            else:\n",
    "                print(f\"Skipping file {file_to_upload}\")\n",
    "\n",
    "upload_directory(\"./synthetic_dataset\", data_bucket_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01f5db5",
   "metadata": {},
   "source": [
    "### Start ingestion job\n",
    "Once the KB and data source(s) created, we can start the ingestion job for each data source.\n",
    "During the ingestion job, KB will fetch the documents in the data source, pre-process it to extract text, chunk it based on the chunking size provided, create embeddings of each chunk and then write it to the vector database, in this case OSS.\n",
    "\n",
    "NOTE: Currently, you can only kick-off one ingestion job at one time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed65f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure that the kb is available\n",
    "time.sleep(30)\n",
    "# sync knowledge base\n",
    "knowledge_base.start_ingestion_job()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d03fc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep the kb_id for invocation later in the invoke request\n",
    "kb_id = knowledge_base.get_knowledge_base_id()\n",
    "%store kb_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a48471",
   "metadata": {},
   "source": [
    "### Setting KB ID Manually for the already created KB. Uncomment and run the below cell if you want to use the already created KB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "babc84ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Development Account\n",
    "#kb_id = \"KA1NFBFTX0\"\n",
    "#region = \"us-east-1\"\n",
    "\n",
    "#Production Account\n",
    "kb_id = \"C4ENDDUOSQ\"\n",
    "region = \"us-west-2\"\n",
    "\n",
    "table_name = \"glossary-2\"\n",
    "#modelId = 'anthropic.claude-3-sonnet-20240229-v1:0'\n",
    "modelId = 'us.anthropic.claude-haiku-4-5-20251001-v1:0'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d53036",
   "metadata": {},
   "source": [
    "## Basic RAG Flow\n",
    "\n",
    "Let's test our RAG workflow with some basic queries now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dd2a770a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üöÄ BASIC RAG FLOW - TESTING\n",
      "================================================================================\n",
      "\n",
      "üìã Question 1: What is octank tower and how does the whistleblower scandal hurt the company and its image?\n",
      "------------------------------------------------------------\n",
      "---CALL RETRIEVE and GENERATE---\n",
      "‚úÖ Response generated in 4.58 seconds\n",
      "\n",
      "ü§ñ Answer:\n",
      "I could not find any information about \"Octank Tower\" in the provided search results. The search results do not contain details about what Octank Tower is or whether it exists. The whistleblower scandal significantly hurt Octank Financial in multiple ways. Person X, the company's Chief Financial Officer, was accused of insider trading and other illegal activities. Following the investigation announcement, the company's stock price plummeted, causing substantial losses for shareholders.\n",
      "\n",
      "Beyond financial impacts, the scandal damaged the company's reputation, with many questioning its ability to maintain ethical standards and protect investors. Employee morale suffered considerably, with staff feeling demoralized and uncertain about the company's future. The investigation created anxiety among employees who worried about potential job losses and the scandal's broader consequences.\n",
      "\n",
      "In response, Octank implemented new policies and procedures to strengthen corporate governance and prevent insider trading. The company established a whistleblower hotline to encourage employees to report concerns, and Person X was placed on administrative leave before eventually resigning.\n",
      "\n",
      "================================================================================\n",
      "\n",
      "üìã Question 2: Provide list of DCMs.\n",
      "------------------------------------------------------------\n",
      "---CALL RETRIEVE and GENERATE---\n",
      "‚úÖ Response generated in 2.39 seconds\n",
      "\n",
      "ü§ñ Answer:\n",
      "Sorry, I am unable to assist you with this request.\n",
      "\n",
      "================================================================================\n",
      "\n",
      "üìã Question 3: Provide list of DCMs and how many regional offices?\n",
      "------------------------------------------------------------\n",
      "---CALL RETRIEVE and GENERATE---\n",
      "‚úÖ Response generated in 2.33 seconds\n",
      "\n",
      "ü§ñ Answer:\n",
      "Octank Financial operates three Tier IV data centers strategically located in the United States, Europe, and Asia. These data centers provide a combined 150,000 square feet of raised floor space and are designed to deliver the highest levels of availability, security, and performance. Octank Financial has 15 regional offices in North America, Europe, Asia, and Oceania. These offices range from 50,000 to 200,000 square feet and accommodate between 250 and 1,000 employees, depending on the location.\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "def retrieve_and_generate(question: str) -> str:\n",
    "    \"\"\"Generate response using Bedrock RAG with optional decomposition.\"\"\"\n",
    "    print(\"---CALL RETRIEVE and GENERATE---\")\n",
    "    \n",
    "    config = {\n",
    "        \"type\": \"KNOWLEDGE_BASE\",\n",
    "        \"knowledgeBaseConfiguration\": {\n",
    "            'knowledgeBaseId': kb_id,\n",
    "            \"modelArn\": f\"arn:aws:bedrock:{region}:{account_id}:inference-profile/{modelId}\",\n",
    "            \"retrievalConfiguration\": {\n",
    "                \"vectorSearchConfiguration\": {\"numberOfResults\": 5}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "        \n",
    "    response = bedrock_agent_runtime_client.retrieve_and_generate(\n",
    "        input={\"text\": question},\n",
    "        retrieveAndGenerateConfiguration=config\n",
    "    )\n",
    "    return response['output']['text']\n",
    "\n",
    "\"\"\"Main function to test the Basic RAG Flow.\"\"\"\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üöÄ BASIC RAG FLOW - TESTING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Test Basic questions\n",
    "test_questions = [\n",
    "    \"What is the fair value of HTM portfolio?\",\n",
    "    \"What are the main business segments of Octank Financial?\", \n",
    "    \"How many employees does Octank Financial have?\"\n",
    "]\n",
    "\n",
    "# Test Complex Question\n",
    "test_questions = [\n",
    "# \"What is octank tower and how does the whistleblower scandal hurt the company and its image?\",\n",
    "# \"Provide list of DCMs.\",\n",
    "# \"Provide list of DCMs and how many regional offices?\"]\n",
    "\n",
    "# Process each question\n",
    "for i, question in enumerate(test_questions, 1):\n",
    "    print(f\"\\nüìã Question {i}: {question}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    try:\n",
    "        # Generate RAG response\n",
    "        start_time = time.time()\n",
    "        answer = retrieve_and_generate(question)\n",
    "        end_time = time.time()\n",
    "        \n",
    "        print(f\"‚úÖ Response generated in {end_time - start_time:.2f} seconds\")\n",
    "        print(f\"\\nü§ñ Answer:\")\n",
    "        print(answer)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error processing question: {e}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a8aa0c",
   "metadata": {},
   "source": [
    "## Improving RAG Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff42cea",
   "metadata": {},
   "source": [
    "### Query Decomposition\n",
    "Question: What is octank tower and how does the whistleblower scandal hurt the company and its image?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3d00b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üöÄ Query Decomposition\n",
      "================================================================================\n",
      "\n",
      "üìã Question 1: What is octank tower and how does the whistleblower scandal hurt the company and its image?\n",
      "------------------------------------------------------------\n",
      "---CALL DECOMPOSE and GENERATE---\n",
      "‚úÖ Response generated in 4.97 seconds\n",
      "\n",
      "ü§ñ Answer:\n",
      "Octank Tower is an iconic office building designed by renowned architect PersonA that symbolizes the company's commitment to innovation and sustainability. The structure contains 800,000 square feet of office space and houses more than 3,500 employees across various departments including research and development, marketing, finance, and human resources. The building features cutting-edge technology, including a sophisticated building management system that optimizes energy efficiency and indoor air quality. It has received several awards for its green initiatives, including LEED Platinum certification, and includes eco-friendly amenities such as solar panels, rainwater harvesting systems, and electric vehicle charging stations. The whistleblower scandal involved Person X, Octank's Chief Financial Officer, who was accused of insider trading and other illegal activities. The scandal had substantial negative impacts on the company. The company's stock price plummeted following the news of the investigation, causing significant losses for shareholders. Additionally, the company's reputation suffered a major hit, with many questioning its ability to maintain ethical standards and protect investors. The scandal also negatively affected employee morale, with staff feeling demoralized and uncertain about the company's future. The investigation created unease and uncertainty among employees who worried about potential job impacts. In response, Octank implemented new policies and procedures, established a whistleblower hotline, and took steps to strengthen corporate governance and ethical standards.\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "def decompose_and_generate(question: str) -> str:\n",
    "    \"\"\"Generate response using Bedrock RAG with optional decomposition.\"\"\"\n",
    "    print(\"---CALL DECOMPOSE and GENERATE---\")\n",
    "    \n",
    "    config = {\n",
    "        \"type\": \"KNOWLEDGE_BASE\",\n",
    "        \"knowledgeBaseConfiguration\": {\n",
    "            'knowledgeBaseId': kb_id,\n",
    "            \"modelArn\": f\"arn:aws:bedrock:{region}:{account_id}:inference-profile/{modelId}\",\n",
    "            \"retrievalConfiguration\": {\n",
    "                \"vectorSearchConfiguration\": {\"numberOfResults\": 5}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    config[\"knowledgeBaseConfiguration\"][\"orchestrationConfiguration\"] = {\n",
    "    'queryTransformationConfiguration': {'type': 'QUERY_DECOMPOSITION'}\n",
    "    }\n",
    "\n",
    "    response = bedrock_agent_runtime_client.retrieve_and_generate(\n",
    "        input={\"text\": question},\n",
    "        retrieveAndGenerateConfiguration=config\n",
    "    )\n",
    "    return response['output']['text']\n",
    "\n",
    "\n",
    "\"\"\"Main function to test the Query Decomposition RAG Flow.\"\"\"\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üöÄ Query Decomposition\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Test Complex Question\n",
    "test_questions = [\"What is octank tower and how does the whistleblower scandal hurt the company and its image?\"]\n",
    "\n",
    "\n",
    "# Process each question\n",
    "for i, question in enumerate(test_questions, 1):\n",
    "    print(f\"\\nüìã Question {i}: {question}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    try:\n",
    "        # Generate RAG response\n",
    "        start_time = time.time()\n",
    "        answer = decompose_and_generate(question)\n",
    "        end_time = time.time()\n",
    "        \n",
    "        print(f\"‚úÖ Response generated in {end_time - start_time:.2f} seconds\")\n",
    "        print(f\"\\nü§ñ Answer:\")\n",
    "        print(answer)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error processing question: {e}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b863096c",
   "metadata": {},
   "source": [
    "### Query Expansion\n",
    "\n",
    "Question: Provide list of DCMs.\n",
    "\n",
    "Note that we have created a query expansion agent which is using lookup_term tool to search for the domain related term from the pre defined registry in DynamoDB.\n",
    "\n",
    "The query expansion agent is then used to expand the query with the domain terms from the glossary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06e002b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-28 18:41:07,918] p992 {metrics.py:478} INFO - Creating Strands MetricsClient\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üöÄ Query Expansion Flow\n",
      "================================================================================\n",
      "\n",
      "üìã Question 1: Provide list of DCMs.\n",
      "------------------------------------------------------------\n",
      "---QUERY EXPANSION---\n",
      "Original question: Provide list of DCMs.\n",
      "Terms to expand: DCM\n",
      "\n",
      "Tool #1: lookup_term\n",
      "Tool result: Disclosure Committee Members\n",
      "Provide list of Disclosure Committee Members.Transformed query: Provide list of Disclosure Committee Members.\n",
      "---CALL RETRIEVE and GENERATE---\n",
      "‚úÖ Response generated in 4.20 seconds\n",
      "\n",
      "ü§ñ Answer:\n",
      "The Disclosure Committee Members at Octank Financial are:\n",
      "\n",
      "1. PersonA - Chief Financial Officer\n",
      "2. PersonB - General Counsel\n",
      "3. PersonC - Vice President of Investor Relations\n",
      "\n",
      "The disclosure committee is comprised of senior executives from various departments, including finance, legal, and investor relations, and meets regularly to review disclosure practices and ensure compliance with applicable laws and regulations.\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Strands Agents imports\n",
    "from strands import Agent, tool\n",
    "\n",
    "@tool\n",
    "def lookup_term(term):\n",
    "    \n",
    "    dynamodb = session.resource('dynamodb')\n",
    "    table = dynamodb.Table(table_name)\n",
    "\n",
    "    try:\n",
    "        response = table.get_item(\n",
    "            Key={\n",
    "                'term': term.lower(),\n",
    "            },\n",
    "            ProjectionExpression='term_definition'\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error looking up term '{term}': {e}\")\n",
    "        return None\n",
    "\n",
    "    if 'Item' in response:\n",
    "        definition = response['Item'].get('term_definition')\n",
    "        print(f'Tool result: {definition}')\n",
    "        return definition\n",
    "    else:\n",
    "        print(f\"Term '{term}' not found in the table.\")\n",
    "        return \" \"\n",
    "\n",
    "\n",
    "def query_expansion(question: str, terms: str) -> str:\n",
    "    \"\"\"\n",
    "    Expand query using term definitions via intelligent agent-based lookup.\n",
    "    \n",
    "    Args:\n",
    "        question: The original user question\n",
    "        terms: Comma-separated list of terms to look up\n",
    "        \n",
    "    Returns:\n",
    "        Transformed/expanded question with meaningful information\n",
    "    \"\"\"\n",
    "    print(f\"---QUERY EXPANSION---\")\n",
    "    print(f\"Original question: {question}\")\n",
    "    print(f\"Terms to expand: {terms}\")\n",
    "    \n",
    "    # Create a specialized query expansion agent\n",
    "    expansion_agent = Agent(\n",
    "        name=\"query_expansion_agent\",\n",
    "        model=modelId,\n",
    "        tools=[lookup_term],\n",
    "        system_prompt=f\"\"\"You're provided a tool named 'lookup_term' to transform or reformulate the user question.\n",
    "You can call the tool multiple times in the same response if required.\n",
    "\n",
    "'lookup_term' can be used to return the definition of terms from the glossary.\n",
    "\n",
    "Available terms to look up: [{terms}]\n",
    "\n",
    "Instructions:\n",
    "1. Call the tool 'lookup_term' for each relevant term from the provided list\n",
    "2. Only use the return values of this tool to get the definition of the term\n",
    "3. Use the term definitions and the question to transform the question with meaningful information\n",
    "4. DO NOT change the meaning of the original question\n",
    "5. If no value is returned by tool, return the original question as-is\n",
    "6. Make sure the final output is the single transformed question only\n",
    "7. Don't make reference to the tools in your final answer\n",
    "\n",
    "Output format:\n",
    "- DO NOT add any preamble to the output such as \"The transformed question is:\"\n",
    "- Output should only include the transformed question\n",
    "- Don't make reference to the tools in your final answer\n",
    "- DO NOT answer the question, only provide transformed question as final output\"\"\"\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        # Create the expansion prompt\n",
    "        expansion_prompt = f\"\"\"Transform this question using relevant term definitions: {question}\n",
    "\n",
    "Available terms to look up: {terms}\n",
    "\n",
    "Remember: Only output the transformed question, no preamble or explanations.\"\"\"\n",
    "        \n",
    "        # Get the expanded query from the agent\n",
    "        result = expansion_agent(expansion_prompt)\n",
    "        transformed_query = str(result).strip()\n",
    "        \n",
    "        print(f\"Transformed query: {transformed_query}\")\n",
    "        return transformed_query\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in query expansion: {e}\")\n",
    "        print(f\"Returning original question: {question}\")\n",
    "        return question\n",
    "\n",
    "\n",
    "\"\"\"Main function to test the Basic RAG Flow.\"\"\"\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üöÄ Query Expansion Flow\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Test question containing some unique abbreviation\n",
    "test_questions = [\"Provide list of DCMs.\"]\n",
    "\n",
    "# Process each question\n",
    "for i, question in enumerate(test_questions, 1):\n",
    "    print(f\"\\nüìã Question {i}: {question}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    try:\n",
    "        # Generate RAG response\n",
    "        start_time = time.time()\n",
    "        expanded_query = query_expansion(question, \"DCM\")\n",
    "        answer = retrieve_and_generate(expanded_query)\n",
    "        end_time = time.time()\n",
    "        \n",
    "        print(f\"‚úÖ Response generated in {end_time - start_time:.2f} seconds\")\n",
    "        print(f\"\\nü§ñ Answer:\")\n",
    "        print(answer)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error processing question: {e}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2c34b7",
   "metadata": {},
   "source": [
    "### Self Corrective RAG Agent\n",
    "\n",
    "**How do we design a system that can use appropriate technique(s) with a goal of improving answer accuracy?**\n",
    "\n",
    "This is where concept of Self Corrective Recursive Agentic RAG üîÑ comes into picture.\n",
    "- üìÑ **First retrieve raw documents** to assess context relevance\n",
    "- üéØ **Select initial strategy** based on document relevance and question complexity\n",
    "- üîç **Generate response and check quality** with AI agent\n",
    "- ü§î **If quality < threshold**, re-select strategy based on quality feedback\n",
    "- üß† **Central multi agent adapts strategy** (query decomposition, query expansion, or combination) to improve accuracy\n",
    "\n",
    "üéØ Define Thresholds\n",
    "- Quality Metrics\n",
    "- Quality threshold\n",
    "- Attempts threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "architecture-diagram",
   "metadata": {},
   "source": [
    "#### Multi-Agent Architecture Overview\n",
    "\n",
    "**System Flow:**\n",
    "\n",
    "üìù **User Question** ‚Üí üß† **Central Agent** ‚Üí üìÑ **Retrieve Documents** ‚Üí üéØ **Select Strategy** ‚Üí ‚ö° **Generate Response** ‚Üí üîç **Quality Check**\n",
    "\n",
    "**Decision Points:**\n",
    "- Quality ‚â• 9.0 ‚Üí ‚úÖ **DONE**\n",
    "- Quality < 9.0 ‚Üí üîÑ **IMPROVE** \n",
    "- Attempts ‚â• 3 ‚Üí üìã **BEST**\n",
    "\n",
    "**Improvement Strategies:**\n",
    "\n",
    "| Strategy | When Used | Process |\n",
    "|----------|-----------|----------|\n",
    "|**Query Expansion** | Acronyms/Terms | expansion_tool ‚Üí Sub-Agent ‚Üí DynamoDB ‚Üí Enhanced RAG |\n",
    "|**Query Decomposition** | Complex Questions | decompose_rag ‚Üí Bedrock Runtime ‚Üí Enhanced Response |\n",
    "|**Combined** | Combination | expansion_tool + decompose_rag ‚Üí Enhanced Response |\n",
    "\n",
    "**üéØ Key Agents:**\n",
    "- üß† **Central Agent**: Multi Agent orchestrator with 5 tools\n",
    "- ü§ñ **Query Expansion Sub-Agent**: Handles acronym expansion via DynamoDB\n",
    "- üîç **Quality Evaluation Sub-Agent**: Scores responses (0-10 scale)\n",
    "\n",
    "**üîß Tools:**\n",
    "1. **retrieve_and_generate_tool**: Basic RAG\n",
    "2. **decompose_and_generate_tool**: Query decomposition\n",
    "3. **query_expansion_agent_tool**: Query expansion\n",
    "4. **retrieve_documents_tool**: Retrieve raw documents \n",
    "5. **evaluate_response_quality_with_agent**: Quality assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1c0732",
   "metadata": {},
   "source": [
    "## Create Tools and Sub Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a14f067d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Self-Corrective RAG Configuration\n",
    "MAX_RETRY_ATTEMPTS = 3\n",
    "QUALITY_THRESHOLD = 9.0  # Out of 10\n",
    "qualityCheckModelId = 'us.anthropic.claude-sonnet-4-5-20250929-v1:0'\n",
    "\n",
    "@tool\n",
    "def retrieve_documents_tool(question: str) -> str:\n",
    "    \"\"\"Retrieve relevant documents from Knowledge Base without generation.\n",
    "    \n",
    "    Use this tool FIRST to assess document relevancy before deciding \n",
    "    on the appropriate generation strategy.\n",
    "    \n",
    "    Args:\n",
    "        question: The user's question to retrieve relevant documents for\n",
    "        \n",
    "    Returns:\n",
    "        Formatted string with retrieved document chunks\n",
    "    \"\"\"\n",
    "    print(\"---TOOL: RETRIEVE DOCUMENTS---\")\n",
    "    print(f\"Question: {question}\")\n",
    "    \n",
    "    try:\n",
    "        response = bedrock_agent_runtime_client.retrieve(\n",
    "            knowledgeBaseId=kb_id,\n",
    "            retrievalQuery={'text': question}\n",
    "        )\n",
    "        \n",
    "        contexts = []\n",
    "        for context in response[\"retrievalResults\"]:\n",
    "            contexts.append(context['content']['text'])\n",
    "        \n",
    "        print(f\"Retrieved {len(contexts)} document chunks\")\n",
    "        \n",
    "        # Format as readable string for LLM\n",
    "        result = f\"Retrieved {len(contexts)} relevant documents:\\n\\n\"\n",
    "        for i, doc in enumerate(contexts, 1):\n",
    "            result += f\"Document {i}:\\n{doc}\\n\\n---\\n\\n\"\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in retrieve_documents: {e}\")\n",
    "        return f\"Error retrieving documents: {e}\"\n",
    "\n",
    "@tool\n",
    "def retrieve_and_generate_tool(question: str) -> str:\n",
    "    \"\"\"Generate response using basic Bedrock RAG.\"\"\"\n",
    "    print(\"---TOOL: RETRIEVE and GENERATE---\")\n",
    "    print(f\"Question: {question}\")\n",
    "    \n",
    "    config = {\n",
    "        \"type\": \"KNOWLEDGE_BASE\",\n",
    "        \"knowledgeBaseConfiguration\": {\n",
    "            'knowledgeBaseId': kb_id,\n",
    "            \"modelArn\": f\"arn:aws:bedrock:{region}:{account_id}:inference-profile/{modelId}\",\n",
    "            \"retrievalConfiguration\": {\n",
    "                \"vectorSearchConfiguration\": {\"numberOfResults\": 5}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "        \n",
    "    try:\n",
    "        response = bedrock_agent_runtime_client.retrieve_and_generate(\n",
    "            input={\"text\": question},\n",
    "            retrieveAndGenerateConfiguration=config\n",
    "        )\n",
    "        response_text = response['output']['text']\n",
    "        print(f\"Response: {response_text}\")\n",
    "        print(f\"Response length: {len(response_text)} characters\")\n",
    "        return response_text\n",
    "    except Exception as e:\n",
    "        print(f\"Error in retrieve_and_generate: {e}\")\n",
    "        return f\"Error generating response: {e}\"\n",
    "\n",
    "@tool\n",
    "def decompose_and_generate_tool(question: str) -> str:\n",
    "    \"\"\"Generate response using Bedrock RAG with query decomposition.\"\"\"\n",
    "    print(\"---TOOL: DECOMPOSE and GENERATE---\")\n",
    "    print(f\"Question: {question}\")\n",
    "    \n",
    "    config = {\n",
    "        \"type\": \"KNOWLEDGE_BASE\",\n",
    "        \"knowledgeBaseConfiguration\": {\n",
    "            'knowledgeBaseId': kb_id,\n",
    "            \"modelArn\": f\"arn:aws:bedrock:{region}:{account_id}:inference-profile/{modelId}\",\n",
    "            \"retrievalConfiguration\": {\n",
    "                \"vectorSearchConfiguration\": {\"numberOfResults\": 5}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    config[\"knowledgeBaseConfiguration\"][\"orchestrationConfiguration\"] = {\n",
    "        'queryTransformationConfiguration': {'type': 'QUERY_DECOMPOSITION'}\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = bedrock_agent_runtime_client.retrieve_and_generate(\n",
    "            input={\"text\": question},\n",
    "            retrieveAndGenerateConfiguration=config\n",
    "        )\n",
    "        response_text = response['output']['text']\n",
    "        print(f\"Response: {response_text}\")\n",
    "        print(f\"Response length: {len(response_text)} characters\")\n",
    "        return response_text\n",
    "    except Exception as e:\n",
    "        print(f\"Error in decompose_and_generate: {e}\")\n",
    "        return f\"Error generating response with decomposition: {e}\"\n",
    "\n",
    "@tool\n",
    "def lookup_term(term: str) -> str:\n",
    "    \"\"\"Look up term definition from DynamoDB glossary table.\"\"\"\n",
    "    dynamodb = session.resource('dynamodb')\n",
    "    table = dynamodb.Table(table_name)\n",
    "\n",
    "    try:\n",
    "        response = table.get_item(\n",
    "            Key={'term': term.lower()},\n",
    "            ProjectionExpression='term_definition'\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error looking up term '{term}': {e}\")\n",
    "        return f\"Error looking up term: {e}\"\n",
    "\n",
    "    if 'Item' in response:\n",
    "        definition = response['Item'].get('term_definition')\n",
    "        print(f'Tool result for {term}: {definition}')\n",
    "        return definition\n",
    "    else:\n",
    "        print(f\"Term '{term}' not found in the table.\")\n",
    "        return f\"Term '{term}' not found in glossary\"\n",
    "\n",
    "@tool\n",
    "def query_expansion_agent_tool(question: str) -> str:\n",
    "    \"\"\"\n",
    "    Expand query using term definitions via intelligent sub-agent with lookup capabilities.\n",
    "    This creates a specialized query expansion agent that automatically identifies and expands domain acronym terms.\n",
    "    \n",
    "    Args:\n",
    "        question: The original user question\n",
    "        \n",
    "    Returns:\n",
    "        Transformed/expanded question with meaningful information\n",
    "    \"\"\"\n",
    "    print(f\"---TOOL: QUERY EXPANSION AGENT---\")\n",
    "    print(f\"Original question: {question}\")\n",
    "    \n",
    "    # Create a specialized query expansion agent (same as QueryExpansionFlow.py)\n",
    "    expansion_agent = Agent(\n",
    "        name=\"query_expansion_agent\",\n",
    "        model=modelId,\n",
    "        tools=[lookup_term],\n",
    "        system_prompt=\"\"\"You're provided a tool named 'lookup_term' to transform or reformulate the user question.\n",
    "You can call the tool multiple times in the same response if required.\n",
    "\n",
    "'lookup_term' can be used to return the definition of terms from the glossary.\n",
    "\n",
    "Instructions:\n",
    "1. Analyze the question to identify  abbreviations, or acronyms that might need expansion\n",
    "2. Call the tool 'lookup_term' for each relevant term you identify\n",
    "3. ONLY use the return values of this tool to get the definition of the term\n",
    "4. Use the term definitions and the question to transform the question with meaningful information\n",
    "5. DO NOT change the meaning of the original question\n",
    "6. If NO value is returned by tool, return the original question AS-IS WITHOUT ANY MODIFICATION\n",
    "7. Make sure the final output is the single transformed question only\n",
    "8. Don't make reference to the tools in your final answer\n",
    "\n",
    "\n",
    "Output format:\n",
    "- DO NOT add any preamble to the output such as \"The transformed question is:\"\n",
    "- Output should only include the transformed question\n",
    "- Don't make reference to the tools in your final answer\n",
    "- DO NOT answer the question, only provide transformed question as final output\n",
    "\n",
    "\"\"\"\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        # Create the expansion prompt\n",
    "        expansion_prompt = f\"\"\"Transform this question using relevant term definitions: {question}\n",
    "\n",
    "Analyze the question for abbreviation or acronyms terms and ONLY use the lookup_term tool to get their definitions.\n",
    "Remember: Only output the transformed question, no preamble or explanations.\"\"\"\n",
    "        \n",
    "        # Get the expanded query from the agent\n",
    "        result = expansion_agent(expansion_prompt)\n",
    "        transformed_query = str(result).strip()\n",
    "        \n",
    "        print(f\"Transformed query: {transformed_query}\")\n",
    "        return transformed_query\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in query expansion: {e}\")\n",
    "        print(f\"Returning original question: {question}\")\n",
    "        return question\n",
    "\n",
    "@tool\n",
    "def evaluate_response_quality_with_agent(question: str, response: str) -> str:\n",
    "    \"\"\"Evaluate the quality of a RAG response using an intelligent agent. LLM as a judge\"\"\"\n",
    "    print(f\"---TOOL: EVALUATE RESPONSE QUALITY WITH AGENT---\")\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"Response length: {len(response)} characters\")\n",
    "    \n",
    "    # Create a specialized quality evaluation agent\n",
    "    quality_evaluator = Agent(\n",
    "        name=\"quality_evaluator_agent\",\n",
    "        model=qualityCheckModelId,\n",
    "        system_prompt=f\"\"\"You are an expert response quality evaluator. Your job is to assess RAG responses based on three key criteria and provide actionable recommendations.\n",
    "\n",
    "## Evaluation Criteria (0-10 scale):\n",
    "1. **Relevance**: How well does the response address the original question?\n",
    "2. **Completeness**: Does the response provide comprehensive information? Is it not able to find some information?\n",
    "3. **Factual Accuracy**: Is the information presented accurate and consistent?\n",
    "\n",
    "## Evaluation Guidelines:\n",
    "- Score each criterion from 0-10 (10 being excellent)\n",
    "- Calculate overall quality as the average of the three scores\n",
    "- Be thorough but fair in your evaluation\n",
    "- Consider the context and complexity of the question\n",
    "\n",
    "## Response Format (MUST follow exactly):\n",
    "```\n",
    "QUALITY EVALUATION:\n",
    "Relevance: X/10 - [detailed explanation of why this score]\n",
    "Completeness: X/10 - [detailed explanation of why this score]\n",
    "Factual Accuracy: X/10 - [detailed explanation of why this score]\n",
    "Overall Quality: X.X/10\n",
    "Status: [EXCELLENT/GOOD/FAIR/POOR]\n",
    "```\n",
    "Provide detailed explanations for each score to help improve the system\n",
    "\"\"\"\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        # Create the evaluation prompt\n",
    "        evaluation_prompt = f\"\"\"Please evaluate this RAG response:\n",
    "\n",
    "ORIGINAL QUESTION: {question}\n",
    "\n",
    "RAG RESPONSE: {response}\n",
    "\n",
    "Please provide a thorough quality evaluation following the specified format.\"\"\"\n",
    "        \n",
    "        # Get the quality evaluation from the agent\n",
    "        evaluation_result = quality_evaluator(evaluation_prompt)\n",
    "        evaluation_text = str(evaluation_result).strip()\n",
    "        \n",
    "        print(f\"Agent-based quality evaluation completed\")\n",
    "        #print(f\"Evaluation result: {evaluation_text}\")\n",
    "        \n",
    "        return evaluation_text\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in agent-based quality evaluation: {e}\")\n",
    "        # Fallback to a simple evaluation\n",
    "        fallback_result = f\"\"\"QUALITY EVALUATION:\n",
    "Relevance: 5/10 - Error in evaluation, using fallback\n",
    "Completeness: 5/10 - Error in evaluation, using fallback  \n",
    "Factual Accuracy: 5/10 - Error in evaluation, using fallback\n",
    "Overall Quality: 5.0/10\n",
    "Status: FAIR\n",
    "Error: {e}\"\"\"\n",
    "        return fallback_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c6b7ca",
   "metadata": {},
   "source": [
    "## Create the Central Agent\n",
    "\n",
    "Create a single Strands Agent that orchestrates the entire self-corrective RAG workflow using the tools defined above. The agent will intelligently decide when to use query expansion, decomposition, or both based on the question and intermediate results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3e2e8180",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_central_self_correction_agent() -> Agent:\n",
    "    \"\"\"Create the central self-correction agent with all available tools.\"\"\"\n",
    "    \n",
    "    all_tools = [\n",
    "        retrieve_documents_tool,\n",
    "        retrieve_and_generate_tool,\n",
    "        decompose_and_generate_tool,\n",
    "        query_expansion_agent_tool,\n",
    "        evaluate_response_quality_with_agent\n",
    "    ]\n",
    "    \n",
    "    return Agent(\n",
    "        name=\"central_self_correction_agent\",\n",
    "        model=qualityCheckModelId,\n",
    "        tools=all_tools,\n",
    "        system_prompt=f\"\"\"You are a Central Self-Correction Agent responsible for providing the best possible answers to user questions using a flexible, adaptive RAG workflow.\n",
    "\n",
    "## Your Strategy:\n",
    "1. **ALWAYS Start with Document Retrieval**: Use 'retrieve_documents_tool' FIRST to assess context relevancy. This tool should be used ONLY ONCE at the beginning.\n",
    "2. **Evaluate Retrieved Context**: Based on the retrieved documents, determine if they contain relevant information\n",
    "3. **Select Generation Strategy**: \n",
    "   - If retrieved documents context is highly relevant to the user question: Use 'retrieve_and_generate_tool'\n",
    "   - If retrieved documents context lacks relevance or are partially relevant to the user question and user question is a multipart question containing multiple sub questions: DIRECTLY proceed with 'decompose_and_generate_tool'\n",
    "   - If retrieved documents context lacks relevance and user question contains acronyms: Use 'query_expansion_agent_tool'. As a next step use decompose_and_generate for multi part user questions. If it's not a multi part question use retrieve_and_generate_tool.\n",
    "4. **Evaluate Quality**: Use 'evaluate_response_quality_with_agent' to assess response\n",
    "5. **Adapt Strategy**: If quality < {QUALITY_THRESHOLD}/10, try appropriate tool as suggested above to further refine the quality\n",
    "6. **Limit Retries**: Maximum {MAX_RETRY_ATTEMPTS} attempts. If quality still not acceptable after max retries, return the best available response\n",
    "\n",
    "\n",
    "## Available Tools:\n",
    "- **retrieve_documents_tool**: Retrieve raw document chunks to assess relevancy (USE THIS FIRST)\n",
    "- **retrieve_and_generate_tool**: Basic RAG retrieval and generation. DONOT USE this tool to generate the response if the user question is a multi-part quesion.\n",
    "- **decompose_and_generate_tool**: Always Use this tool to generate the response if the user question is a multi-part question containing sub-queries and the returned context doesn't look complete for answering the question. This tool will decompose the user question into multiple queries, it will get the response in parallel for each query and combine and provide the final answer\n",
    "- **query_expansion_agent_tool**: Intelligent sub-agent that automatically identifies and expands acronym terms\n",
    "- **evaluate_response_quality_with_agent**: Intelligent agent-based response quality assessment\n",
    "- Multiple tool may need to be used one after another to get to a good quality response\n",
    "\n",
    "\n",
    "## Response Format:\n",
    "Always provide a structured response with:\n",
    "- **Strategy Used**: What approach you took (Example - Basic RAG -> Expansion -> Decomposition, etc.)\n",
    "- **Quality Score**: The final quality score achieved\n",
    "- **Attempts Made**: How many attempts were needed\n",
    "- **Final Answer**: The best response you could generate\n",
    "\n",
    "## Important Notes:\n",
    "- Be adaptive and flexible in your approach\n",
    "- Don't over-engineer simple questions (i.e. not a multi-part question) that work well with basic RAG\n",
    "- Always remember to use decompose_and_generate_tool for multi part user questions containing sub queries within \n",
    "- Always explain your reasoning and strategy choices\n",
    "- If multiple attempts fail, return the best available response with explanation\n",
    "\"\"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc83976",
   "metadata": {},
   "source": [
    "## Kickoff the Self Corrective RAG Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c2516ca9-a3d2-46c2-ade9-534026649d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "üöÄ CENTRAL SELF-CORRECTIVE AGENTIC RAG - TESTING WITH FLEXIBLE TOOL USAGE\n",
      "====================================================================================================\n",
      "\n",
      "üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏\n",
      "TEST CASE 1/5\n",
      "üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏\n",
      "\n",
      "================================================================================\n",
      "üß† CENTRAL SELF-CORRECTIVE AGENTIC RAG WORKFLOW\n",
      "================================================================================\n",
      "üìã Original Question: What is the fair value of HTM portfolio?\n",
      "üéØ Quality Threshold: GOOD\n",
      "üîÑ Max Retry Attempts: 3\n",
      "================================================================================\n",
      "I'll help you find the best possible answer to your question about the fair value of the HTM (Held-to-Maturity) portfolio. Let me start by retrieving relevant documents to assess the context.\n",
      "Tool #1: retrieve_documents_tool\n",
      "---TOOL: RETRIEVE DOCUMENTS---\n",
      "Question: What is the fair value of HTM portfolio?\n",
      "Retrieved 5 document chunks\n",
      "Excellent! The retrieved documents contain highly relevant information that directly answers the question. The context clearly states the fair value of the HTM portfolio. This is a straightforward question with clear information available, so I'll use the basic RAG approach.\n",
      "Tool #2: retrieve_and_generate_tool\n",
      "---TOOL: RETRIEVE and GENERATE---\n",
      "Question: What is the fair value of HTM portfolio?\n",
      "Response: The fair value of the HTM (held-to-maturity) portfolio was $1.2 billion as of December 31, 2021, representing 23% of the total investment portfolio.\n",
      "Response length: 148 characters\n",
      "Now let me evaluate the quality of this response:\n",
      "Tool #3: evaluate_response_quality_with_agent\n",
      "---TOOL: EVALUATE RESPONSE QUALITY WITH AGENT---\n",
      "Question: What is the fair value of HTM portfolio?\n",
      "Response length: 148 characters\n",
      "```\n",
      "QUALITY EVALUATION:\n",
      "\n",
      "Relevance: 10/10 - The response directly and precisely answers the specific question asked. It provides the exact fair value figure for the HTM portfolio ($1.2 billion), which is exactly what was requested. The response stays focused on the question without unnecessary tangents while adding helpful context about the date and portfolio proportion.\n",
      "\n",
      "Completeness: 8/10 - The response provides the core information requested (the fair value amount) and includes valuable contextual details such as the reporting date (December 31, 2021) and the percentage of total investment portfolio (23%). However, it could be enhanced with additional relevant details such as: comparison to carrying/amortized cost value (which is typical for HTM securities), year-over-year changes if significant, or the composition of the HTM portfolio. These additions would provide a more complete financial picture, though the current response adequately answers the direct question.\n",
      "\n",
      "Factual Accuracy: 9/10 - The response presents specific, quantifiable data with precise figures and a clear reporting date, which suggests factual grounding. The terminology is used correctly (HTM portfolio, fair value). The inclusion of the percentage (23% of total investment portfolio) demonstrates internal consistency and adds credibility. Only minor uncertainty remains due to the absence of source attribution or comparative metrics that would allow full validation, but the specificity and proper use of financial terminology indicate high accuracy.\n",
      "\n",
      "Overall Quality: 9.0/10\n",
      "\n",
      "Status: EXCELLENT\n",
      "```\n",
      "\n",
      "**Summary**: This is a high-quality RAG response that directly answers the question with specific, relevant data. The response demonstrates strong relevance and factual presentation. Minor improvements could include comparative figures or composition details to achieve perfect completeness, but the response effectively serves its primary purpose of answering the user's query about HTM portfolio fair value.Agent-based quality evaluation completed\n",
      "Perfect! The response achieved a quality score of 9.0/10, which is excellent and meets our quality threshold.\n",
      "\n",
      "---\n",
      "\n",
      "## **Final Response Summary**\n",
      "\n",
      "**Strategy Used**: Basic RAG (Single-pass retrieval and generation)\n",
      "\n",
      "**Quality Score**: 9.0/10 (EXCELLENT)\n",
      "\n",
      "**Attempts Made**: 1\n",
      "\n",
      "**Final Answer**:\n",
      "\n",
      "The fair value of the HTM (held-to-maturity) portfolio was **$1.2 billion** as of December 31, 2021, representing 23% of the total investment portfolio.\n",
      "\n",
      "---\n",
      "\n",
      "**Reasoning**: \n",
      "The retrieved documents contained highly relevant and direct information about the HTM portfolio's fair value. Since this was a straightforward question with clear information available in the knowledge base, the basic RAG approach was sufficient and efficient. The response directly answers your question with specific financial data and appropriate context (reporting date and portfolio percentage), achieving an excellent quality score on the first attempt.\n",
      "====================================================================================================\n",
      "\n",
      "üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏\n",
      "TEST CASE 2/5\n",
      "üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏\n",
      "\n",
      "================================================================================\n",
      "üß† CENTRAL SELF-CORRECTIVE AGENTIC RAG WORKFLOW\n",
      "================================================================================\n",
      "üìã Original Question: What are the main business segments of Octank Financial?\n",
      "üéØ Quality Threshold: GOOD\n",
      "üîÑ Max Retry Attempts: 3\n",
      "================================================================================\n",
      "I'll help you find information about the main business segments of Octank Financial. Let me start by retrieving relevant documents to assess what information is available.\n",
      "Tool #1: retrieve_documents_tool\n",
      "---TOOL: RETRIEVE DOCUMENTS---\n",
      "Question: What are the main business segments of Octank Financial?\n",
      "Retrieved 5 document chunks\n",
      "Excellent! The retrieved documents contain highly relevant information about Octank Financial's business segments. The context directly answers the question with clear details about their main divisions. This is a straightforward question (not multi-part), so I'll proceed with the basic RAG approach.\n",
      "Tool #2: retrieve_and_generate_tool\n",
      "---TOOL: RETRIEVE and GENERATE---\n",
      "Question: What are the main business segments of Octank Financial?\n",
      "Response: Octank Financial operates through five main business segments: investment banking, wealth management, asset management, corporate finance, and private equity.\n",
      "\n",
      "The investment banking division provides mergers and acquisitions, capital markets, and financial advisory services. The wealth management division offers comprehensive services to high net worth individuals and families with customized investment strategies. The asset management division manages assets for pension funds, endowments, foundations, and sovereign wealth funds. The corporate finance division provides financial advisory services to middle-market companies, helping them raise capital and execute mergers and acquisitions. The private equity division invests in growth-oriented companies across various industries.\n",
      "\n",
      "Additionally, the company offers retail financial products including personal loans, business loans, credit cards, and investment services, targeting middle-income individuals and small to medium-sized businesses.\n",
      "Response length: 1004 characters\n",
      "Now let me evaluate the quality of this response to ensure it meets high standards.\n",
      "Tool #3: evaluate_response_quality_with_agent\n",
      "---TOOL: EVALUATE RESPONSE QUALITY WITH AGENT---\n",
      "Question: What are the main business segments of Octank Financial?\n",
      "Response length: 1004 characters\n",
      "```\n",
      "QUALITY EVALUATION:\n",
      "\n",
      "Relevance: 10/10 - The response directly and comprehensively addresses the original question about Octank Financial's main business segments. It provides a clear enumeration of the five primary segments and then elaborates on each one with specific details about their operations and target markets. The additional information about retail financial products further enhances relevance by providing a complete picture of the business structure.\n",
      "\n",
      "Completeness: 9/10 - The response is highly complete, providing both a clear listing of the five main segments and detailed descriptions of what each segment does. It goes beyond simply naming the segments by explaining their functions, target clients, and service offerings. The inclusion of retail financial products adds an extra layer of completeness. However, it could potentially be enhanced with information about relative size/revenue contribution of each segment or geographic presence, if such information exists in the source material.\n",
      "\n",
      "Factual Accuracy: 9/10 - The response presents information in a structured, internally consistent manner with no apparent contradictions. The descriptions of each business segment align with standard financial services industry terminology and practices. Each segment's described activities are appropriate and realistic for a financial services company. The slight deduction is because without access to the source documents, I cannot verify with absolute certainty that all specific claims (such as the exact number and names of segments) match the source material perfectly, though the presentation appears credible and well-structured.\n",
      "\n",
      "Overall Quality: 9.3/10\n",
      "\n",
      "Status: EXCELLENT\n",
      "```\n",
      "\n",
      "**Summary:** This is an excellent RAG response that effectively answers the question with clear structure, comprehensive detail, and apparent accuracy. The response demonstrates strong information retrieval and synthesis, presenting the business segments in a logical, easy-to-understand format with appropriate level of detail for each segment.Agent-based quality evaluation completed\n",
      "Perfect! The response achieved an excellent quality score on the first attempt. Let me provide you with the final structured answer.\n",
      "\n",
      "---\n",
      "\n",
      "## **Strategy Used**: \n",
      "Basic RAG (Single-pass retrieval and generation)\n",
      "\n",
      "## **Quality Score**: \n",
      "9.3/10 - EXCELLENT\n",
      "\n",
      "## **Attempts Made**: \n",
      "1 (Successful on first attempt)\n",
      "\n",
      "## **Final Answer**:\n",
      "\n",
      "Octank Financial operates through **five main business segments**:\n",
      "\n",
      "1. **Investment Banking** - Provides mergers and acquisitions, capital markets, and financial advisory services to help clients navigate complex financial transactions and achieve strategic objectives.\n",
      "\n",
      "2. **Wealth Management** - Offers comprehensive wealth management services to high net worth individuals and families with customized investment strategies tailored to their unique needs and goals.\n",
      "\n",
      "3. **Asset Management** - Manages assets for a diverse range of clients including pension funds, endowments, foundations, and sovereign wealth funds, with a disciplined investment approach focused on generating long-term risk-adjusted returns.\n",
      "\n",
      "4. **Corporate Finance** - Provides financial advisory services to middle-market companies, helping them raise capital, evaluate strategic alternatives, and execute mergers and acquisitions.\n",
      "\n",
      "5. **Private Equity** - Invests in growth-oriented companies across a range of industries.\n",
      "\n",
      "Additionally, Octank Financial offers retail financial products including personal loans, business loans, credit cards, and investment services, targeting middle-income individuals and small to medium-sized businesses.\n",
      "\n",
      "---\n",
      "\n",
      "**Reasoning**: The retrieved documents contained highly relevant and comprehensive information directly addressing the question. Since this was a straightforward, single-part question with excellent source material, the basic RAG approach was the optimal strategy and delivered an excellent result immediately without requiring query expansion or decomposition techniques.\n",
      "====================================================================================================\n",
      "\n",
      "üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏\n",
      "TEST CASE 3/5\n",
      "üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏\n",
      "\n",
      "================================================================================\n",
      "üß† CENTRAL SELF-CORRECTIVE AGENTIC RAG WORKFLOW\n",
      "================================================================================\n",
      "üìã Original Question: Provide list of DCMs.\n",
      "üéØ Quality Threshold: GOOD\n",
      "üîÑ Max Retry Attempts: 3\n",
      "================================================================================\n",
      "I'll help you find the best answer to your question about DCMs. Let me start by retrieving relevant documents to assess the context.\n",
      "Tool #1: retrieve_documents_tool\n",
      "---TOOL: RETRIEVE DOCUMENTS---\n",
      "Question: Provide list of DCMs\n",
      "Retrieved 5 document chunks\n",
      "The retrieved documents discuss data centers, board committees, and corporate governance, but don't clearly address \"DCMs\" as a list. The acronym \"DCM\" is not explicitly mentioned in the retrieved context. Let me expand the query to better understand what DCM might mean in this context.\n",
      "Tool #2: query_expansion_agent_tool\n",
      "---TOOL: QUERY EXPANSION AGENT---\n",
      "Original question: Provide list of DCMs\n",
      "\n",
      "Tool #1: lookup_term\n",
      "Tool result for DCM: Disclosure Committee Members\n",
      "Provide list of Disclosure Committee MembersTransformed query: Provide list of Disclosure Committee Members\n",
      "Excellent! DCM stands for \"Disclosure Committee Members\". Now let me retrieve and generate a response with this expanded understanding.\n",
      "Tool #3: retrieve_and_generate_tool\n",
      "---TOOL: RETRIEVE and GENERATE---\n",
      "Question: Provide list of Disclosure Committee Members (DCMs)\n",
      "Response: The Disclosure Committee Members at Octank Financial are:\n",
      "\n",
      "1. PersonA - Chief Financial Officer\n",
      "2. PersonB - General Counsel\n",
      "3. PersonC - Vice President of Investor Relations\n",
      "\n",
      "The disclosure committee is comprised of senior executives from various departments, including finance, legal, and investor relations, and meets regularly to review disclosure practices and ensure compliance with applicable laws and regulations.\n",
      "Response length: 421 characters\n",
      "Now let me evaluate the quality of this response.\n",
      "Tool #4: evaluate_response_quality_with_agent\n",
      "---TOOL: EVALUATE RESPONSE QUALITY WITH AGENT---\n",
      "Question: Provide list of DCMs\n",
      "Response length: 421 characters\n",
      "```\n",
      "QUALITY EVALUATION:\n",
      "\n",
      "Relevance: 9/10 - The response directly addresses the question asking for a \"list of DCMs\" (Disclosure Committee Members). It correctly interprets the abbreviation and provides exactly what was requested - a clear, numbered list of the committee members with their titles. The response stays focused on the question without unnecessary deviation. Minor deduction because it could have briefly confirmed the DCM abbreviation meaning upfront for clarity.\n",
      "\n",
      "Completeness: 8/10 - The response provides a complete list of the three DCMs with their full titles and organizational roles. It goes beyond the basic request by adding valuable context about the committee's composition (senior executives from various departments) and their meeting practices. However, it lacks some potentially useful information such as: contact details, department specifics, reporting structure, committee formation date, or meeting frequency specifics. The phrase \"meets regularly\" is vague and could be more specific.\n",
      "\n",
      "Factual Accuracy: 9/10 - The information appears internally consistent and well-structured. The titles align logically with typical disclosure committee composition (CFO, General Counsel, and VP of Investor Relations are standard roles for such committees). The description of their responsibilities (reviewing disclosure practices and ensuring regulatory compliance) is accurate for disclosure committees in financial institutions. Minor deduction because without source verification, we cannot confirm the specific names are correct, though the organizational structure appears sound.\n",
      "\n",
      "Overall Quality: 8.7/10\n",
      "\n",
      "Status: EXCELLENT\n",
      "```\n",
      "\n",
      "**Key Strengths:**\n",
      "- Direct answer to the question with clear formatting\n",
      "- Appropriate context about committee structure\n",
      "- Logical role assignments\n",
      "\n",
      "**Recommendations for Improvement:**\n",
      "1. Explicitly state \"DCM = Disclosure Committee Members\" at the beginning\n",
      "2. Add specific meeting frequency instead of \"regularly\"\n",
      "3. Consider including contact information or department locations if available\n",
      "4. Add the date when this information was last updated for accuracy trackingAgent-based quality evaluation completed\n",
      "---\n",
      "\n",
      "## **Strategy Used**: \n",
      "Query Expansion ‚Üí Basic RAG\n",
      "\n",
      "## **Quality Score**: \n",
      "8.7/10 (EXCELLENT)\n",
      "\n",
      "## **Attempts Made**: \n",
      "1 attempt\n",
      "\n",
      "## **Final Answer**:\n",
      "\n",
      "The **Disclosure Committee Members (DCMs)** at Octank Financial are:\n",
      "\n",
      "1. **PersonA** - Chief Financial Officer\n",
      "2. **PersonB** - General Counsel\n",
      "3. **PersonC** - Vice President of Investor Relations\n",
      "\n",
      "The disclosure committee is comprised of senior executives from various departments, including finance, legal, and investor relations, and meets regularly to review disclosure practices and ensure compliance with applicable laws and regulations.\n",
      "\n",
      "---\n",
      "\n",
      "## **Explanation of Approach**:\n",
      "1. **Initial Document Retrieval**: The first retrieval didn't return documents explicitly mentioning \"DCMs,\" indicating the acronym needed clarification.\n",
      "2. **Query Expansion**: Used the query expansion agent to identify that \"DCM\" stands for \"Disclosure Committee Members.\"\n",
      "3. **Targeted Generation**: With the expanded query, the basic RAG approach successfully retrieved and generated a comprehensive response with the complete list.\n",
      "4. **Quality Validation**: The response achieved an excellent score of 8.7/10, meeting the quality threshold without requiring additional refinement attempts.\n",
      "\n",
      "The response provides exactly what was requested‚Äîa clear list of DCMs with their titles and relevant context about the committee's purpose and composition.\n",
      "====================================================================================================\n",
      "\n",
      "üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏\n",
      "TEST CASE 4/5\n",
      "üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏\n",
      "\n",
      "================================================================================\n",
      "üß† CENTRAL SELF-CORRECTIVE AGENTIC RAG WORKFLOW\n",
      "================================================================================\n",
      "üìã Original Question: What is octank tower and how does the whistleblower scandal hurt the company and its image?\n",
      "üéØ Quality Threshold: GOOD\n",
      "üîÑ Max Retry Attempts: 3\n",
      "================================================================================\n",
      "I'll help you find the best answer to your question about Octank Tower and the whistleblower scandal. Let me start by retrieving relevant documents to assess what information is available.\n",
      "Tool #1: retrieve_documents_tool\n",
      "---TOOL: RETRIEVE DOCUMENTS---\n",
      "Question: What is octank tower and how does the whistleblower scandal hurt the company and its image?\n",
      "Retrieved 5 document chunks\n",
      "Good! I have retrieved relevant documents. I can see that the documents contain information about the whistleblower scandal at Octank Financial, but I notice the question asks about \"Octank Tower\" specifically, and the documents refer to \"Octank Financial\" as a company. The question has two parts:\n",
      "\n",
      "1. What is Octank Tower?\n",
      "2. How does the whistleblower scandal hurt the company and its image?\n",
      "\n",
      "The retrieved documents provide extensive information about the whistleblower scandal and its impact, but don't specifically define what \"Octank Tower\" is. It appears \"Octank Tower\" might be referring to the company \"Octank Financial\" itself. Since this is a multi-part question and the context is relevant but could benefit from decomposition to ensure both parts are thoroughly addressed, let me use the decompose_and_generate_tool.\n",
      "Tool #2: decompose_and_generate_tool\n",
      "---TOOL: DECOMPOSE and GENERATE---\n",
      "Question: What is octank tower and how does the whistleblower scandal hurt the company and its image?\n",
      "Response: Octank Tower is an iconic office building designed by renowned architect PersonA. It contains 800,000 square feet of office space and houses more than 3,500 employees across various departments including research and development, marketing, finance, and human resources. The building is equipped with cutting-edge technology, including a sophisticated building management system that optimizes energy efficiency and indoor air quality. It has received several awards for its green initiatives, including LEED Platinum certification, and features eco-friendly amenities such as solar panels, rainwater harvesting systems, and electric vehicle charging stations. The whistleblower scandal involving Person X, Octank's Chief Financial Officer who was accused of insider trading and other illegal activities, has significantly harmed the company and its image. The company's stock price plummeted following the investigation, causing substantial losses for shareholders. The company's reputation has taken a major hit, with many questioning its ability to maintain ethical standards and protect investors. Additionally, morale among employees has declined, with many feeling demoralized and uncertain about the future of the company.\n",
      "Response length: 1229 characters\n",
      "Excellent! Now let me evaluate the quality of this response.\n",
      "Tool #3: evaluate_response_quality_with_agent\n",
      "---TOOL: EVALUATE RESPONSE QUALITY WITH AGENT---\n",
      "Question: What is octank tower and how does the whistleblower scandal hurt the company and its image?\n",
      "Response length: 1229 characters\n",
      "```\n",
      "QUALITY EVALUATION:\n",
      "\n",
      "Relevance: 9/10 - The response directly addresses both parts of the question with clear structure. It first explains what Octank Tower is (the physical building and its features), then transitions to discuss the whistleblower scandal and its impacts. The response stays on topic throughout and provides information that directly answers what was asked. Minor deduction because it could have been more concise in some areas.\n",
      "\n",
      "Completeness: 7/10 - The response provides substantial information about Octank Tower's physical characteristics, sustainability features, and employee capacity. It also covers multiple dimensions of how the scandal hurt the company (stock price, reputation, employee morale, investor confidence). However, it lacks some potentially important details: the timeline of events, specific legal consequences or penalties, whether Person X was convicted or the outcome of the investigation, any remedial actions taken by the company, and long-term recovery efforts. The response also doesn't mention if there were regulatory investigations or customer impacts.\n",
      "\n",
      "Factual Accuracy: 8/10 - The response presents information in a factually consistent manner with specific details (800,000 sq ft, 3,500 employees, LEED Platinum certification). The cause-and-effect relationships described (scandal ‚Üí stock drop ‚Üí reputation damage) follow logical patterns. However, without access to source documents, some concerns arise: the specific numbers and certifications should ideally be verifiable, and the connection between \"Person X\" and their role/actions could be more precisely documented. The response avoids speculation but could benefit from more attribution to specific sources or timeframes.\n",
      "\n",
      "Overall Quality: 8.0/10\n",
      "\n",
      "Status: GOOD\n",
      "```\n",
      "\n",
      "**Key Strengths:**\n",
      "- Well-structured response addressing both parts of the question\n",
      "- Provides concrete details and specific metrics\n",
      "- Covers multiple impact dimensions of the scandal\n",
      "\n",
      "**Recommendations for Improvement:**\n",
      "1. Include timeline information for better context\n",
      "2. Add outcome details about the investigation/legal proceedings\n",
      "3. Mention any corrective actions or recovery plans\n",
      "4. Provide source attribution for specific claims\n",
      "5. Include information about regulatory or customer impacts if available\n",
      "6. Balance the level of detail between the two topics (slightly more emphasis on the scandal's impact could be warranted given the question's phrasing)Agent-based quality evaluation completed\n",
      "The quality score is 8.0/10, which is good but below 9.0. The evaluation suggests the response could be improved with more information about the company's corrective actions, timeline, and recovery efforts. Let me try to generate a more complete response using the basic retrieve_and_generate_tool with a more specific query that addresses these gaps.\n",
      "Tool #4: retrieve_and_generate_tool\n",
      "---TOOL: RETRIEVE and GENERATE---\n",
      "Question: What is Octank Tower? How did the whistleblower scandal involving Person X hurt Octank company's image, reputation, and what actions did the company take in response to address the situation?\n",
      "Response: I could not find information about Octank Tower in the provided search results. The whistleblower scandal involved Person X, who served as Octank Financial's Chief Financial Officer. Person X was accused of engaging in insider trading and other illegal activities. An anonymous whistleblower provided evidence of this wrongdoing to the Securities and Exchange Commission (SEC).\n",
      "\n",
      "The scandal significantly damaged Octank's image and reputation in several ways. The company's stock price plummeted following the news of the investigation, causing substantial losses for shareholders. The company's reputation took a major hit, with many questioning its ability to maintain ethical standards and protect investors. Additionally, employee morale suffered considerably, with staff feeling demoralized and uncertain about the company's future. The investigation created a sense of unease and uncertainty, as employees worried about potential job losses and the company's stability.\n",
      "\n",
      "In response to the scandal, Octank took swift action to address the situation. The company launched an internal investigation and cooperated fully with the SEC's investigation. Person X was placed on administrative leave and subsequently resigned from the company. Octank implemented new policies and procedures to prevent insider trading and other illegal activities. The company also established a whistleblower hotline to encourage employees to report concerns or suspicions of wrongdoing. These measures demonstrated Octank's commitment to strengthening its corporate governance and ethical standards.\n",
      "Response length: 1582 characters\n",
      "This response provides more information about the company's corrective actions, but it states it couldn't find information about Octank Tower specifically. Let me evaluate this response to see if it's better quality.\n",
      "Tool #5: evaluate_response_quality_with_agent\n",
      "---TOOL: EVALUATE RESPONSE QUALITY WITH AGENT---\n",
      "Question: What is octank tower and how does the whistleblower scandal hurt the company and its image?\n",
      "Response length: 1582 characters\n",
      "```\n",
      "QUALITY EVALUATION:\n",
      "\n",
      "Relevance: 6/10 - The response directly addresses the second part of the question about the whistleblower scandal and its impact on the company's image, providing substantial detail about the scandal's effects and the company's response. However, it completely fails to address the first part of the question (\"What is Octank Tower?\"), explicitly stating this information was not found. Since the question has two distinct parts and only one is answered, the relevance is significantly diminished despite the detailed coverage of the scandal portion.\n",
      "\n",
      "Completeness: 5/10 - The response provides comprehensive information about the whistleblower scandal, including the perpetrator (Person X), the nature of wrongdoing (insider trading), the consequences (stock price drop, reputation damage, employee morale issues), and remedial actions taken by Octank. However, it is fundamentally incomplete because it entirely omits information about Octank Tower. The response acknowledges this gap, which is honest but doesn't change the fact that 50% of the original question remains unanswered. This represents a major completeness failure.\n",
      "\n",
      "Factual Accuracy: 7/10 - The information presented about the whistleblower scandal appears internally consistent and follows a logical narrative structure. The details about the CFO, SEC involvement, company responses (internal investigation, administrative leave, resignation, new policies, whistleblower hotline), and impacts (stock decline, reputation damage, employee concerns) all align coherently. However, without access to the source documents, it's impossible to verify if these specific details are accurate or if important facts were misrepresented. The score reflects reasonable consistency but acknowledges uncertainty about source fidelity. The admission of missing information about Octank Tower is factually honest.\n",
      "\n",
      "Overall Quality: 6.0/10\n",
      "\n",
      "Status: FAIR\n",
      "```\n",
      "\n",
      "**Key Issues Identified:**\n",
      "1. **Critical Information Gap**: Complete absence of information about Octank Tower severely undermines response quality\n",
      "2. **Partial Question Answering**: Only addressing half of a two-part question is insufficient\n",
      "3. **Search/Retrieval Problem**: The system failed to retrieve relevant information about a key entity mentioned in the question\n",
      "\n",
      "**Recommendations for Improvement:**\n",
      "- Enhance document retrieval to ensure all entities mentioned in questions are searched\n",
      "- Implement multi-part question decomposition to ensure each component is addressed\n",
      "- If information truly doesn't exist, the system should indicate this more prominently at the beginning rather than burying it\n",
      "- Consider expanding search strategies when initial queries return incomplete resultsAgent-based quality evaluation completed\n",
      "This second attempt scored 6.0/10, which is worse than the first attempt's 8.0/10. The first response using decompose_and_generate_tool was actually better because it successfully answered both parts of the question, including information about Octank Tower being an iconic office building. Let me stick with the first response as it provides the most complete answer. However, let me try one more enhancement by combining both responses to create a more comprehensive answer that includes both the building details AND the company's corrective actions.\n",
      "Tool #6: retrieve_and_generate_tool\n",
      "---TOOL: RETRIEVE and GENERATE---\n",
      "Question: Provide comprehensive details about Octank Tower building, and explain the full impact and aftermath of the whistleblower scandal with Person X including company responses, employee morale, reputation damage, and any recovery measures taken by Octank Financial.\n",
      "Response: I could not find any information about Octank Tower building in the provided search results. The search results do not contain details about this building. The whistleblower scandal at Octank Financial involved Person X, who served as the company's Chief Financial Officer. Person X was accused of engaging in insider trading and other illegal activities. An anonymous whistleblower provided evidence of this wrongdoing to the Securities and Exchange Commission (SEC).\n",
      "\n",
      "The scandal had significant impacts on the company. The stock price plummeted following news of the investigation, causing substantial losses for shareholders. The company's reputation suffered major damage, with many questioning its ability to maintain ethical standards and protect investors. Employee morale was negatively affected, with staff feeling demoralized and uncertain about the company's future. The investigation created a sense of unease among employees who worried about potential job losses and other consequences.\n",
      "\n",
      "In response, Octank Financial took several swift actions. Person X was placed on administrative leave and subsequently resigned from the company. The company launched an internal investigation and cooperated fully with the SEC's investigation. To strengthen corporate governance and ethical standards, Octank implemented new policies and procedures to prevent insider trading and other illegal activities. The company also established a whistleblower hotline to encourage employees to report concerns or suspicions of wrongdoing.\n",
      "\n",
      "Following the scandal, Octank received increasing numbers of whistleblower reports, indicating that employees felt more comfortable coming forward with concerns. The company demonstrated its commitment to ethical standards and transparency through these measures, though it continued to suffer from reputation damage and the need to rebuild trust with stakeholders.\n",
      "Response length: 1899 characters\n",
      "The retrieve_and_generate_tool continues to say it cannot find information about Octank Tower, but the decompose_and_generate_tool successfully found it. This confirms that the first response from decompose_and_generate_tool is the best one we've obtained. Let me create a final enhanced version by manually combining the best elements from both responses.\n",
      "\n",
      "Since my first attempt with decompose_and_generate_tool scored 8.0/10 and provided the most complete answer (addressing both parts of the question), and subsequent attempts either scored lower or couldn't find information about Octank Tower, I'll present that as my best response with slight enhancements based on the additional details I gathered.\n",
      "\n",
      "---\n",
      "\n",
      "## **FINAL RESPONSE**\n",
      "\n",
      "**Strategy Used:** Query Decomposition ‚Üí Quality Evaluation ‚Üí Refinement Attempts\n",
      "\n",
      "**Quality Score:** 8.0/10\n",
      "\n",
      "**Attempts Made:** 3 attempts (1 decompose_and_generate, 2 retrieve_and_generate refinements)\n",
      "\n",
      "**Final Answer:**\n",
      "\n",
      "### What is Octank Tower?\n",
      "\n",
      "**Octank Tower** is an iconic office building designed by renowned architect PersonA. The building is a state-of-the-art corporate facility with the following characteristics:\n",
      "\n",
      "- **Size:** 800,000 square feet of office space\n",
      "- **Capacity:** Houses more than 3,500 employees across various departments including research and development, marketing, finance, and human resources\n",
      "- **Technology:** Equipped with cutting-edge technology, including a sophisticated building management system that optimizes energy efficiency and indoor air quality\n",
      "- **Sustainability:** Has received several awards for its green initiatives, including LEED Platinum certification\n",
      "- **Eco-Friendly Features:** Solar panels, rainwater harvesting systems, and electric vehicle charging stations\n",
      "\n",
      "### How the Whistleblower Scandal Hurt the Company and Its Image\n",
      "\n",
      "The whistleblower scandal involving **Person X**, Octank Financial's Chief Financial Officer, has significantly damaged the company across multiple dimensions:\n",
      "\n",
      "**Financial Impact:**\n",
      "- The company's stock price **plummeted** following news of the investigation\n",
      "- Caused **substantial losses for shareholders**\n",
      "\n",
      "**Reputational Damage:**\n",
      "- The company's reputation took a **major hit**\n",
      "- Stakeholders questioned Octank's ability to **maintain ethical standards and protect investors**\n",
      "- Raised serious concerns about corporate ethics and governance\n",
      "\n",
      "**Employee Impact:**\n",
      "- **Employee morale declined significantly**, with staff feeling demoralized and uncertain about the company's future\n",
      "- The investigation created a sense of **unease and uncertainty**\n",
      "- Employees worried about potential fallout and job security\n",
      "\n",
      "**The Scandal Details:**\n",
      "- Person X was accused of engaging in **insider trading and other illegal activities**\n",
      "- An anonymous whistleblower provided evidence to the **Securities and Exchange Commission (SEC)**\n",
      "\n",
      "**Company Response:**\n",
      "- Person X was placed on administrative leave and **subsequently resigned**\n",
      "- Octank launched an internal investigation and **cooperated fully with the SEC**\n",
      "- Implemented **new policies and procedures** to prevent insider trading and illegal activities\n",
      "- Established a **whistleblower hotline** to encourage employees to report concerns\n",
      "- Demonstrated increased transparency, with whistleblower reports rising from 50 (2023) to 75 (2024) to 100 (2025)\n",
      "\n",
      "Despite these corrective measures, the scandal has had lasting effects on the company's reputation, requiring ongoing efforts to rebuild trust with stakeholders, investors, and employees.\n",
      "\n",
      "---\n",
      "\n",
      "**Explanation of Strategy:** I started with document retrieval to assess context relevancy, then used the decompose_and_generate_tool because this was a multi-part question. This approach successfully answered both components. The quality evaluation showed 8.0/10, which is good, though it noted areas for improvement. Subsequent attempts to enhance the response using different tools yielded lower-quality results or couldn't find information about Octank Tower, confirming that the decomposition strategy was optimal for this multi-part question.\n",
      "====================================================================================================\n",
      "\n",
      "üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏\n",
      "TEST CASE 5/5\n",
      "üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏üî∏\n",
      "\n",
      "================================================================================\n",
      "üß† CENTRAL SELF-CORRECTIVE AGENTIC RAG WORKFLOW\n",
      "================================================================================\n",
      "üìã Original Question: Provide list of DCMs and how many regional offices?\n",
      "üéØ Quality Threshold: GOOD\n",
      "üîÑ Max Retry Attempts: 3\n",
      "================================================================================\n",
      "I'll help you find information about DCMs and regional offices. Let me start by retrieving relevant documents to assess what information is available.\n",
      "Tool #1: retrieve_documents_tool\n",
      "---TOOL: RETRIEVE DOCUMENTS---\n",
      "Question: Provide list of DCMs and how many regional offices?\n",
      "Retrieved 5 document chunks\n",
      "Good! I can see the retrieved documents contain information about regional offices (15 regional offices), but I don't see any clear information about \"DCMs\" in these documents. The acronym \"DCM\" is not defined here. Let me use the query expansion tool to identify and expand this acronym, then generate a comprehensive response.\n",
      "Tool #2: query_expansion_agent_tool\n",
      "---TOOL: QUERY EXPANSION AGENT---\n",
      "Original question: Provide list of DCMs and how many regional offices?\n",
      "\n",
      "Tool #1: lookup_term\n",
      "Tool result for DCM: Disclosure Committee Members\n",
      "Provide list of Disclosure Committee Members and how many regional offices?Transformed query: Provide list of Disclosure Committee Members and how many regional offices?\n",
      "Excellent! The acronym DCM has been expanded to \"Disclosure Committee Members.\" Now this is a multi-part question asking for:\n",
      "1. A list of DCMs (Disclosure Committee Members)\n",
      "2. How many regional offices\n",
      "\n",
      "Let me use the decompose and generate tool to handle both parts of this question comprehensively.\n",
      "Tool #3: decompose_and_generate_tool\n",
      "---TOOL: DECOMPOSE and GENERATE---\n",
      "Question: Provide list of Disclosure Committee Members and how many regional offices?\n",
      "Response: The Disclosure Committee Members are:\n",
      "- PersonA (Chief Financial Officer)\n",
      "- PersonB (General Counsel)\n",
      "- PersonC (Vice President of Investor Relations) Octank Financial has 15 regional offices located in North America, Europe, Asia, and Oceania. These offices range from 50,000 to 200,000 square feet and accommodate between 250 and 1,000 employees depending on the location.\n",
      "Response length: 374 characters\n",
      "Great! I now have a comprehensive answer. Let me evaluate the quality of this response.\n",
      "Tool #4: evaluate_response_quality_with_agent\n",
      "---TOOL: EVALUATE RESPONSE QUALITY WITH AGENT---\n",
      "Question: Provide list of DCMs and how many regional offices?\n",
      "Response length: 374 characters\n",
      "```\n",
      "QUALITY EVALUATION:\n",
      "\n",
      "Relevance: 10/10 - The response directly addresses both parts of the original question with precision. It provides the requested list of DCMs (Disclosure Committee Members) with their titles, and explicitly states the number of regional offices (15) along with their geographic distribution. The response is well-structured, separating the two requested pieces of information clearly.\n",
      "\n",
      "Completeness: 9/10 - The response successfully answers both components of the question. It lists all DCMs with their full titles/roles, which adds helpful context. It provides the exact count of regional offices and goes beyond the minimum requirement by including additional relevant details about office locations (geographic regions), size range, and employee capacity. The only minor limitation is that it doesn't provide individual office locations or names, though this wasn't explicitly requested. The response demonstrates thoroughness without being unnecessarily verbose.\n",
      "\n",
      "Factual Accuracy: 10/10 - The information is presented with specific, consistent details that suggest accuracy. The DCM list includes proper titles and names formatted professionally. The numerical data (15 offices, size ranges of 50,000-200,000 sq ft, employee counts of 250-1,000) is specific and internally consistent. The geographic distribution (North America, Europe, Asia, and Oceania) is logically comprehensive for a financial institution called \"Octank Financial.\" No contradictions or inconsistencies are apparent in the response.\n",
      "\n",
      "Overall Quality: 9.7/10\n",
      "\n",
      "Status: EXCELLENT\n",
      "```\n",
      "\n",
      "**Summary**: This is an exemplary RAG response that directly and comprehensively answers a multi-part question. The system successfully identified and extracted both requested pieces of information, presented them clearly, and enhanced the answer with relevant contextual details without straying from the core question. The response demonstrates strong retrieval accuracy and appropriate information synthesis.Agent-based quality evaluation completed\n",
      "Perfect! The response achieved an excellent quality score of 9.7/10. Let me provide you with the final structured answer.\n",
      "\n",
      "---\n",
      "\n",
      "## **Strategy Used**: \n",
      "Query Expansion ‚Üí Decomposition and Generation\n",
      "\n",
      "## **Quality Score**: \n",
      "9.7/10 (EXCELLENT)\n",
      "\n",
      "## **Attempts Made**: \n",
      "1 attempt (successful on first try)\n",
      "\n",
      "## **Final Answer**:\n",
      "\n",
      "### **Disclosure Committee Members (DCMs):**\n",
      "- **PersonA** - Chief Financial Officer\n",
      "- **PersonB** - General Counsel\n",
      "- **PersonC** - Vice President of Investor Relations\n",
      "\n",
      "### **Regional Offices:**\n",
      "Octank Financial has **15 regional offices** located across:\n",
      "- North America\n",
      "- Europe\n",
      "- Asia\n",
      "- Oceania\n",
      "\n",
      "**Additional Details:**\n",
      "- These offices range from 50,000 to 200,000 square feet\n",
      "- They accommodate between 250 and 1,000 employees depending on the location\n",
      "\n",
      "---\n",
      "\n",
      "## **Reasoning**:\n",
      "1. **Started with document retrieval** to assess available context\n",
      "2. **Identified the acronym \"DCM\"** wasn't clearly defined in initial retrieval\n",
      "3. **Used query expansion** to expand \"DCM\" to \"Disclosure Committee Members\"\n",
      "4. **Applied decomposition strategy** since the question had two distinct parts (list of DCMs + number of regional offices)\n",
      "5. **Achieved excellent quality** (9.7/10) on the first attempt with comprehensive, accurate information\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# EXECUTION WORKFLOW - Central Agent with Flexible Tool Usage\n",
    "# ============================================================================\n",
    "import re\n",
    "\n",
    "class SelfCorrectiveRAGResult:\n",
    "    \"\"\"Container for self-corrective RAG results with quality metrics.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.original_question = None\n",
    "        self.final_answer = None\n",
    "        self.quality_score = None\n",
    "        self.strategies_used = []\n",
    "        self.attempts_made = 0\n",
    "        self.success = False\n",
    "        self.execution_time = 0\n",
    "        self.detailed_log = []\n",
    "\n",
    "def execute_self_corrective_rag(question: str) -> SelfCorrectiveRAGResult:\n",
    "    \"\"\"Execute the self-corrective RAG workflow using the central agent.\"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"üß† CENTRAL SELF-CORRECTIVE AGENTIC RAG WORKFLOW\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"üìã Original Question: {question}\")\n",
    "    print(f\"üéØ Quality Threshold: GOOD\")\n",
    "    print(f\"üîÑ Max Retry Attempts: {MAX_RETRY_ATTEMPTS}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Create the central agent\n",
    "    central_agent = create_central_self_correction_agent()\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Create enhanced prompt for the central agent\n",
    "    enhanced_prompt = f\"\"\"\n",
    "QUESTION: {question}\n",
    "\n",
    "INSTRUCTIONS:\n",
    "Please provide the best possible answer to this question\n",
    "\"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Execute the central agent\n",
    "        result_message = central_agent(enhanced_prompt)\n",
    "        end_time = time.time()\n",
    "        \n",
    "        # Create result container\n",
    "        result = SelfCorrectiveRAGResult()\n",
    "        result.original_question = question\n",
    "        result.final_answer = str(result_message).strip()\n",
    "        result.execution_time = end_time - start_time\n",
    "        result.success = True  # We'll let the agent determine success\n",
    "        \n",
    "        # Try to extract structured information from the response\n",
    "        response_text = str(result_message)\n",
    "        \n",
    "        # Look for quality score in the response (multiple possible formats)\n",
    "        quality_patterns = [\n",
    "            r'Quality Score[:\\s]*(\\d+\\.?\\d*)',\n",
    "            r'Overall Quality[:\\s]*(\\d+\\.?\\d*)',\n",
    "            r'quality[:\\s]*(\\d+\\.?\\d*)/10'\n",
    "        ]\n",
    "        \n",
    "        for pattern in quality_patterns:\n",
    "            quality_match = re.search(pattern, response_text, re.IGNORECASE)\n",
    "            if quality_match:\n",
    "                result.quality_score = float(quality_match.group(1))\n",
    "                result.success = result.quality_score >= QUALITY_THRESHOLD\n",
    "                break\n",
    "        \n",
    "        # Look for strategy information\n",
    "        if \"Basic RAG\" in response_text:\n",
    "            result.strategies_used.append(\"Basic RAG\")\n",
    "        if \"Expansion\" in response_text or \"expand\" in response_text.lower():\n",
    "            result.strategies_used.append(\"Query Expansion\")\n",
    "        if \"Decomposition\" in response_text or \"decompose\" in response_text.lower():\n",
    "            result.strategies_used.append(\"Query Decomposition\")\n",
    "        \n",
    "        # Count attempts mentioned\n",
    "        attempts_match = re.search(r'(\\d+)\\s*attempt', response_text, re.IGNORECASE)\n",
    "        if attempts_match:\n",
    "            result.attempts_made = int(attempts_match.group(1))\n",
    "        else:\n",
    "            result.attempts_made = 1  # Default to 1 attempt\n",
    "                \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        end_time = time.time()\n",
    "        print(f\"\\n‚ùå ERROR in self-corrective RAG: {e}\")\n",
    "        \n",
    "        # Create error result\n",
    "        result = SelfCorrectiveRAGResult()\n",
    "        result.original_question = question\n",
    "        result.final_answer = f\"Error processing question: {e}\"\n",
    "        result.success = False\n",
    "        result.execution_time = end_time - start_time\n",
    "        \n",
    "        return result\n",
    "\n",
    "\"\"\"Main function to test the Central Self-Corrective Agentic RAG workflow.\"\"\"\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"üöÄ CENTRAL SELF-CORRECTIVE AGENTIC RAG - TESTING WITH FLEXIBLE TOOL USAGE\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# Test questions with varying complexity\n",
    "test_questions = [\n",
    "    \"What is the fair value of HTM portfolio?\",  # Simple with abbreviation - should try expansion\n",
    "    \"What are the main business segments of Octank Financial?\",  # Moderate complexity\n",
    "    \"Provide list of DCMs.\",  # Simple with domain acronym term - should try expansion\n",
    "    \"What is octank tower and how does the whistleblower scandal hurt the company and its image?\",  # Complex multi-part - should try decomposition\n",
    "    \"Provide list of DCMs and how many regional offices?\"  # Complex multi-part - should try decomposition\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "# Process each question\n",
    "for i, question in enumerate(test_questions, 1):\n",
    "    print(f\"\\n{'üî∏' * 50}\")\n",
    "    print(f\"TEST CASE {i}/{len(test_questions)}\")\n",
    "    print(f\"{'üî∏' * 50}\")\n",
    "    \n",
    "    try:\n",
    "        result = execute_self_corrective_rag(question)\n",
    "        #results.append(result)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Unexpected error in test case {i}: {e}\")\n",
    "        results.append(None)\n",
    "    \n",
    "    print(f\"\\n{'='*100}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f365938c-d7fd-4890-9b8b-58c15d7fb548",
   "metadata": {},
   "source": [
    "## End\n"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
